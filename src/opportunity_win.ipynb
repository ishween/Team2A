{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specific Data Prep\n",
    "\n",
    "### Analyzing columns to select which one to use as target/label\\\n",
    "\n",
    "NOTE: I did this by accident. In trying to make the lead scoring model, I accidentally created the lead scoring model.\n",
    "\n",
    "Here, I ended up choosing won_deal. The classifier should ultimately come up with a probability that won_deal is either 0 or 1 and classify based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['close_date', 'close_value', 'has_close_date', 'close_value_log', 'deal_stage_ENGAGING', 'deal_stage_LOST', 'deal_stage_PROSPECTING', 'deal_stage_WON', 'days_to_close', 'closed_within_30d', 'agent_closed_deals', 'won_deal']\n",
      "\n",
      "Column: close_date\n",
      "close_date\n",
      "NaN           2089\n",
      "2017-05-22      41\n",
      "2017-06-11      36\n",
      "2017-11-19      34\n",
      "2017-05-20      34\n",
      "2017-08-11      34\n",
      "2017-05-26      34\n",
      "2017-11-07      33\n",
      "2017-11-03      33\n",
      "2017-05-06      33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: close_value\n",
      "close_value\n",
      "0.0     2473\n",
      "NaN     2089\n",
      "54.0      80\n",
      "53.0      57\n",
      "57.0      55\n",
      "59.0      54\n",
      "55.0      52\n",
      "56.0      48\n",
      "51.0      45\n",
      "60.0      44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: has_close_date\n",
      "has_close_date\n",
      "1    6711\n",
      "0    2089\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: close_value_log\n",
      "close_value_log\n",
      "0.000000    2473\n",
      "NaN         2089\n",
      "4.007333      80\n",
      "3.988984      57\n",
      "4.060443      55\n",
      "4.094345      54\n",
      "4.025352      52\n",
      "4.043051      48\n",
      "3.951244      45\n",
      "4.110874      44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: deal_stage_ENGAGING\n",
      "deal_stage_ENGAGING\n",
      "0    7211\n",
      "1    1589\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: deal_stage_LOST\n",
      "deal_stage_LOST\n",
      "0    6327\n",
      "1    2473\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: deal_stage_PROSPECTING\n",
      "deal_stage_PROSPECTING\n",
      "0    8300\n",
      "1     500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: deal_stage_WON\n",
      "deal_stage_WON\n",
      "0    4562\n",
      "1    4238\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: days_to_close\n",
      "days_to_close\n",
      "NaN     2089\n",
      "9.0      311\n",
      "8.0      305\n",
      "1.0      301\n",
      "7.0      301\n",
      "2.0      278\n",
      "10.0     255\n",
      "11.0     226\n",
      "6.0      204\n",
      "5.0      160\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: closed_within_30d\n",
      "closed_within_30d\n",
      "0    5637\n",
      "1    3163\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: agent_closed_deals\n",
      "agent_closed_deals\n",
      "553    747\n",
      "264    706\n",
      "261    695\n",
      "347    451\n",
      "336    448\n",
      "335    438\n",
      "272    362\n",
      "232    317\n",
      "231    311\n",
      "229    310\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column: won_deal\n",
      "won_deal\n",
      "1    6711\n",
      "0    2089\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/cleaned_data.csv\")\n",
    "\n",
    "# Look for deal-related columns\n",
    "cols = [c for c in df.columns if \"deal\" in c.lower() or \"stage\" in c.lower() or \"won\" in c.lower() or \"close\" in c.lower()]\n",
    "print(cols)\n",
    "\n",
    "# Peek at their unique values\n",
    "for c in cols:\n",
    "    print(f\"\\nColumn: {c}\")\n",
    "    print(df[c].value_counts(dropna=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realized theres probably a lot of columns that would help the model \"cheat\" in figuring out if the deal closes as a win or not. Here, I'm trying to drop all columns that do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sales_agent', 'account', 'engage_date', 'close_date', 'close_value',\n",
       "       'sales_price', 'year_established', 'revenue', 'employees',\n",
       "       'office_location', 'has_close_date', 'close_value_log', 'revenue_log',\n",
       "       'employees_log', 'product_GTK 500', 'product_GTX BASIC',\n",
       "       'product_GTX PLUS BASIC', 'product_GTX PLUS PRO', 'product_GTX PRO',\n",
       "       'product_MG ADVANCED', 'product_MG SPECIAL', 'manager_CARA LOSCH',\n",
       "       'manager_CELIA ROUCHE', 'manager_DUSTIN BRINKMANN',\n",
       "       'manager_MELVIN MARXEN', 'manager_ROCCO NEUBERT',\n",
       "       'manager_SUMMER SEWALD', 'regional_office_CENTRAL',\n",
       "       'regional_office_EAST', 'regional_office_WEST', 'series_GTK',\n",
       "       'series_GTX', 'series_MG', 'sector_EMPLOYMENT', 'sector_ENTERTAINMENT',\n",
       "       'sector_FINANCE', 'sector_MARKETING', 'sector_MEDICAL', 'sector_RETAIL',\n",
       "       'sector_SERVICES', 'sector_SOFTWARE', 'sector_TECHNOLGY',\n",
       "       'sector_TELECOMMUNICATIONS', 'subsidiary_of_ACME CORPORATION',\n",
       "       'subsidiary_of_BUBBA GUMP', 'subsidiary_of_GOLDDEX',\n",
       "       'subsidiary_of_INITY', 'subsidiary_of_MASSIVE DYNAMIC',\n",
       "       'subsidiary_of_SONRON', 'subsidiary_of_WAREPHASE',\n",
       "       'deal_stage_ENGAGING', 'deal_stage_LOST', 'deal_stage_PROSPECTING',\n",
       "       'deal_stage_WON', 'sales_price_scaled', 'decade_1970s', 'decade_1980s',\n",
       "       'decade_1990s', 'decade_2000s', 'decade_2010s', 'engage_year',\n",
       "       'engage_month', 'engage_dayofweek', 'days_to_close',\n",
       "       'closed_within_30d', 'account_age', 'rev_per_employee',\n",
       "       'agent_closed_deals', 'won_deal', 'account_win_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sales_agent', 'account', 'engage_date', 'sales_price',\n",
       "       'year_established', 'revenue', 'employees', 'office_location',\n",
       "       'revenue_log', 'employees_log', 'product_GTK 500', 'product_GTX BASIC',\n",
       "       'product_GTX PLUS BASIC', 'product_GTX PLUS PRO', 'product_GTX PRO',\n",
       "       'product_MG ADVANCED', 'product_MG SPECIAL', 'manager_CARA LOSCH',\n",
       "       'manager_CELIA ROUCHE', 'manager_DUSTIN BRINKMANN',\n",
       "       'manager_MELVIN MARXEN', 'manager_ROCCO NEUBERT',\n",
       "       'manager_SUMMER SEWALD', 'regional_office_CENTRAL',\n",
       "       'regional_office_EAST', 'regional_office_WEST', 'series_GTK',\n",
       "       'series_GTX', 'series_MG', 'sector_EMPLOYMENT', 'sector_ENTERTAINMENT',\n",
       "       'sector_FINANCE', 'sector_MARKETING', 'sector_MEDICAL', 'sector_RETAIL',\n",
       "       'sector_SERVICES', 'sector_SOFTWARE', 'sector_TECHNOLGY',\n",
       "       'sector_TELECOMMUNICATIONS', 'subsidiary_of_ACME CORPORATION',\n",
       "       'subsidiary_of_BUBBA GUMP', 'subsidiary_of_GOLDDEX',\n",
       "       'subsidiary_of_INITY', 'subsidiary_of_MASSIVE DYNAMIC',\n",
       "       'subsidiary_of_SONRON', 'subsidiary_of_WAREPHASE', 'sales_price_scaled',\n",
       "       'decade_1970s', 'decade_1980s', 'decade_1990s', 'decade_2000s',\n",
       "       'decade_2010s', 'engage_year', 'engage_month', 'engage_dayofweek',\n",
       "       'account_age', 'rev_per_employee', 'won_deal', 'account_win_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"won_deal\"\n",
    "\n",
    "leak_cols = [\"deal_stage_WON\", \"deal_stage_LOST\", \"deal_stage_ENGAGING\", \"deal_stage_PROSPECTING\", \"close_date\", \"close_value\", \"has_close_date\", \"close_value_log\", \"days_to_close\", \"closed_within_30d\", \"agent_closed_deals\"]\n",
    "\n",
    "df = df.drop(columns=[col for col in leak_cols if col in df.columns])\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['engage_date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# finding all non-numeric columns leftover\n",
    "non_numeric = df.select_dtypes(exclude=['number']).columns\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>account</th>\n",
       "      <th>sales_price</th>\n",
       "      <th>year_established</th>\n",
       "      <th>revenue</th>\n",
       "      <th>employees</th>\n",
       "      <th>office_location</th>\n",
       "      <th>revenue_log</th>\n",
       "      <th>employees_log</th>\n",
       "      <th>product_GTK 500</th>\n",
       "      <th>...</th>\n",
       "      <th>decade_1990s</th>\n",
       "      <th>decade_2000s</th>\n",
       "      <th>decade_2010s</th>\n",
       "      <th>engage_year</th>\n",
       "      <th>engage_month</th>\n",
       "      <th>engage_dayofweek</th>\n",
       "      <th>account_age</th>\n",
       "      <th>rev_per_employee</th>\n",
       "      <th>won_deal</th>\n",
       "      <th>account_win_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>1096</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>718.62</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6.578723</td>\n",
       "      <td>7.803435</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.293554</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>4821</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3178.24</td>\n",
       "      <td>4540.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8.064397</td>\n",
       "      <td>8.420903</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.700053</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>718.62</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6.578723</td>\n",
       "      <td>7.803435</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.293554</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>550</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>2714.90</td>\n",
       "      <td>2641.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.906879</td>\n",
       "      <td>7.879291</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.027982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>550</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>792.46</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6.676403</td>\n",
       "      <td>7.170120</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.610054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3393</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1698.20</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.437913</td>\n",
       "      <td>8.158516</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3393</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1698.20</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.437913</td>\n",
       "      <td>8.158516</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8797</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3393</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1698.20</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.437913</td>\n",
       "      <td>8.158516</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3393</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1698.20</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.437913</td>\n",
       "      <td>8.158516</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3393</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1698.20</td>\n",
       "      <td>3492.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.437913</td>\n",
       "      <td>8.158516</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8800 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sales_agent  account  sales_price  year_established  revenue  employees  \\\n",
       "0              20        8         1096            2001.0   718.62     2448.0   \n",
       "1               6       38         4821            2002.0  3178.24     4540.0   \n",
       "2               6        8           55            2001.0   718.62     2448.0   \n",
       "3              20       10          550            1998.0  2714.90     2641.0   \n",
       "4              29       34          550            1982.0   792.46     1299.0   \n",
       "...           ...      ...          ...               ...      ...        ...   \n",
       "8795           25       35         3393            1995.0  1698.20     3492.0   \n",
       "8796           25       35         3393            1995.0  1698.20     3492.0   \n",
       "8797           25       35         3393            1995.0  1698.20     3492.0   \n",
       "8798           25       35         3393            1995.0  1698.20     3492.0   \n",
       "8799           25       35         3393            1995.0  1698.20     3492.0   \n",
       "\n",
       "      office_location  revenue_log  employees_log  product_GTK 500  ...  \\\n",
       "0                  14     6.578723       7.803435                0  ...   \n",
       "1                  14     8.064397       8.420903                0  ...   \n",
       "2                  14     6.578723       7.803435                0  ...   \n",
       "3                  14     7.906879       7.879291                0  ...   \n",
       "4                  14     6.676403       7.170120                0  ...   \n",
       "...               ...          ...            ...              ...  ...   \n",
       "8795               14     7.437913       8.158516                0  ...   \n",
       "8796               14     7.437913       8.158516                0  ...   \n",
       "8797               14     7.437913       8.158516                0  ...   \n",
       "8798               14     7.437913       8.158516                0  ...   \n",
       "8799               14     7.437913       8.158516                0  ...   \n",
       "\n",
       "      decade_1990s  decade_2000s  decade_2010s  engage_year  engage_month  \\\n",
       "0                0             1             0       2016.0          10.0   \n",
       "1                0             1             0       2016.0          10.0   \n",
       "2                0             1             0       2016.0          10.0   \n",
       "3                1             0             0       2016.0          10.0   \n",
       "4                0             0             0       2016.0          10.0   \n",
       "...            ...           ...           ...          ...           ...   \n",
       "8795             1             0             0          NaN           NaN   \n",
       "8796             1             0             0          NaN           NaN   \n",
       "8797             1             0             0          NaN           NaN   \n",
       "8798             1             0             0          NaN           NaN   \n",
       "8799             1             0             0          NaN           NaN   \n",
       "\n",
       "      engage_dayofweek  account_age  rev_per_employee  won_deal  \\\n",
       "0                  3.0         24.0          0.293554         1   \n",
       "1                  1.0         23.0          0.700053         1   \n",
       "2                  1.0         24.0          0.293554         1   \n",
       "3                  1.0         27.0          1.027982         1   \n",
       "4                  1.0         43.0          0.610054         1   \n",
       "...                ...          ...               ...       ...   \n",
       "8795               NaN         30.0          0.486312         0   \n",
       "8796               NaN         30.0          0.486312         0   \n",
       "8797               NaN         30.0          0.486312         0   \n",
       "8798               NaN         30.0          0.486312         0   \n",
       "8799               NaN         30.0          0.486312         0   \n",
       "\n",
       "      account_win_rate  \n",
       "0             0.920792  \n",
       "1             0.941176  \n",
       "2             0.920792  \n",
       "3             0.966942  \n",
       "4             0.873563  \n",
       "...                ...  \n",
       "8795          0.118769  \n",
       "8796          0.118769  \n",
       "8797          0.118769  \n",
       "8798          0.118769  \n",
       "8799          0.118769  \n",
       "\n",
       "[8800 rows x 58 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"engage_date\", axis=1) # dropping because its still not numerical (can't be used by model) and thus far we haven't been able to find any relevancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (3.0.5)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.5\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(columns=[label])\n",
    "# y = df[label]\n",
    "\n",
    "# CLEAN UP LATER TO FIGURE OUT WHY NON NUMERICALS WERE COMING THROUGH\n",
    "\n",
    "y = df[label].astype(int)          # target\n",
    "X = df.drop(columns=[label])       # features\n",
    "X = X.select_dtypes(include='number')         # keep only numeric features\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X = imp.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set\n",
    "# Potential TODO: Go back and do K-fold validation. Figure out how to do test, training, and validation sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # stratify preserves class proportions\n",
    "\n",
    "# Models and baseline hyperparameters to be used for model selection:\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators = 400,\n",
    "        max_depth = 12,\n",
    "        min_samples_split = 5,\n",
    "        n_jobs = -1,\n",
    "        random_state = 42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators = 600,\n",
    "        max_depth = 6,\n",
    "        learning_rate = 0.05,\n",
    "        subsample = 0.9,\n",
    "        colsample_bytree = 0.9,\n",
    "        reg_lambda = 1.0,\n",
    "        objective = \"binary:logistic\",\n",
    "        eval_metric = \"logloss\",\n",
    "        n_jobs = -1,\n",
    "        random_state = 42\n",
    "    ),\n",
    "    \"LogReg_L2\": LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        n_jobs = -1,\n",
    "        C = 0.5\n",
    "    )\n",
    "}\n",
    "\n",
    "# Helper function to evaluate each model\n",
    "def evaluate(name, model):\n",
    "    \n",
    "    print(\"Fitting model:\", name)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        y_proba = MinMaxScaler().fit_transform(model.decision_function(X_test).reshape(-1,1)).ravel()\n",
    "    else:\n",
    "        y_proba = y_pred  # fallback (not ideal)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy:  {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}   Recall: {rec:.3f}   F1: {f1:.3f}   ROC-AUC: {auc:.3f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForest\n",
      "\n",
      "=== RandomForest ===\n",
      "Accuracy:  0.947\n",
      "Precision: 0.935   Recall: 1.000   F1: 0.966   ROC-AUC: 0.972\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 324   94]\n",
      " [   0 1342]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.775     0.873       418\n",
      "           1      0.935     1.000     0.966      1342\n",
      "\n",
      "    accuracy                          0.947      1760\n",
      "   macro avg      0.967     0.888     0.920      1760\n",
      "weighted avg      0.950     0.947     0.944      1760\n",
      "\n",
      "Fitting model: XGBoost\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy:  0.950\n",
      "Precision: 0.949   Recall: 0.987   F1: 0.968   ROC-AUC: 0.969\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 347   71]\n",
      " [  17 1325]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.953     0.830     0.887       418\n",
      "           1      0.949     0.987     0.968      1342\n",
      "\n",
      "    accuracy                          0.950      1760\n",
      "   macro avg      0.951     0.909     0.928      1760\n",
      "weighted avg      0.950     0.950     0.949      1760\n",
      "\n",
      "Fitting model: LogReg_L2\n",
      "\n",
      "=== LogReg_L2 ===\n",
      "Accuracy:  0.920\n",
      "Precision: 0.911   Recall: 0.992   F1: 0.950   ROC-AUC: 0.870\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 288  130]\n",
      " [  11 1331]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.963     0.689     0.803       418\n",
      "           1      0.911     0.992     0.950      1342\n",
      "\n",
      "    accuracy                          0.920      1760\n",
      "   macro avg      0.937     0.840     0.877      1760\n",
      "weighted avg      0.923     0.920     0.915      1760\n",
      "\n",
      "\n",
      "Best model by Accuracy: XGBoost (0.950)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = {name: evaluate(name, m) for name, m in models.items()}\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\nBest model by Accuracy: {best_model_name} ({results[best_model_name]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further To Do:\n",
    "1. Figure out why missing values/non numeric columns were slipping through to model testing\n",
    "2. Figure out if model is overfitting. Consider: K-fold Cross Validation, Out of Sample Validation\n",
    "3. Hyperparameter tuning\n",
    "4. Very low priority: Experiment with Neural Networks? Hypothetically, it's not the best approach to this problem, but I'm curious to see how it compares and why\n",
    "5. Research Gradio, mock presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

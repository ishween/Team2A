{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d278404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ElasticNetCV from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/utils.py:1185: UserWarning: Expected 1 arguments for function <function handle_query at 0x307b1eef0>, received 2.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/utils.py:1193: UserWarning: Expected maximum 1 arguments for function <function handle_query at 0x307b1eef0>, received 2.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/utils.py:1185: UserWarning: Expected 1 arguments for function <function handle_query at 0x307b1f250>, received 2.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/utils.py:1193: UserWarning: Expected maximum 1 arguments for function <function handle_query at 0x307b1f250>, received 2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://3e87b7a9fe9ef20903.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3e87b7a9fe9ef20903.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/queueing.py\", line 763, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/blocks.py\", line 2106, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/blocks.py\", line 1586, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/utils.py\", line 1015, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/chat_interface.py\", line 541, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/gradio/chat_interface.py\", line 902, in _submit_fn\n",
      "    response = await run_sync(self.fn, *inputs, limiter=self.limiter)\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/anaconda3/envs/gradio-ollama/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "TypeError: handle_query() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from agents.chatbot import CRMChatbot\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "#data \n",
    "root = Path.cwd().parent \n",
    "accounts_data = pd.read_csv(root / \"data\" / \"accounts_with_id.csv\")\n",
    "opportunities_data = pd.read_csv(root / \"data\" / \"opp_data_with_id.csv\")\n",
    "\n",
    "\n",
    "opp_win = pickle.load(open(os.path.join(os.getcwd(),  \"..\", \"models\", \"opportunity_win_model.pkl\"), \"rb\"))\n",
    "lead_scoring = pickle.load(open(os.path.join(os.getcwd(), \"..\", \"models\", \"lead_scoring_model.pkl\"), \"rb\"))['classifier']\n",
    "account_health = pickle.load(open(os.path.join(os.getcwd(), \"..\", \"models\", \"account_health_model.pkl\"), \"rb\"))['model']\n",
    "\n",
    "'''\n",
    "opp_win = pickle.load(open(root / \"models\" / \"opportunity_win_model.pkl\", \"rb\"))\n",
    "lead_scoring = pickle.load(open(root / \"models\" / \"lead_scoring_model.pkl\", \"rb\"))['classifier']\n",
    "account_health = pickle.load(open(root / \"models\" / \"account_health_model.pkl\", \"rb\"))['model']\n",
    "'''\n",
    "ml_models = {\n",
    "    \"opportunity_win_model\": opp_win,\n",
    "    \"lead_scoring_model\": lead_scoring,\n",
    "    \"account_health_model\": account_health\n",
    "}\n",
    "\n",
    "chromadb.api.client.SharedSystemClient.clear_system_cache() # fixing chromadb  bug?\n",
    "client = chromadb.PersistentClient(path=str(root / \"data\" / \"chroma_db\"))\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "chatbot = CRMChatbot(client, embedder, ml_models, accounts_data, opportunities_data, leads=pd.DataFrame(), activities=pd.DataFrame())\n",
    "\n",
    "def handle_query(query):\n",
    "    return chatbot.process_natural_language_query(query)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Salesforce 2A Assistant\")\n",
    "    gr.Markdown(\n",
    "        \"Hi! I can help you explore Salesforce CRM opportunities and accounts.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"- `Accounts with more than 100 employees and located in Romania`\\n\"\n",
    "        \"- `Opportunities in the medical sector closed in 2017`\\n\"\n",
    "        \"- `Deals won by Moses Frase`\"\n",
    "    )\n",
    "\n",
    "\n",
    "    chat = gr.ChatInterface(\n",
    "        fn=handle_query,\n",
    "        title=\"Salesforce 2A CRM AI Assisstant\",\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio-ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

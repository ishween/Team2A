{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://d050a6428b9dc86d10.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d050a6428b9dc86d10.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/original_merged_data.csv\")\n",
    "\n",
    "sentence_transformer = SentenceTransformer(\"../models/sales_sentence_transformer\")\n",
    "\n",
    "# reconnect to persistent chromadb client\n",
    "client = chromadb.PersistentClient(path=\"../chroma_store\")\n",
    "\n",
    "# get account collection\n",
    "account_collection = client.get_collection(\"sales_accounts\")\n",
    "\n",
    "def get_result_from_query(query, collection, model, n_results=10):\n",
    "    # Encode the query using the sentence transformer\n",
    "    query_emb = model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "    # Query Chroma using the embedding\n",
    "    res = collection.query(\n",
    "        query_embeddings=[query_emb],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def chat_fn(message, history):\n",
    "    res = get_result_from_query(\n",
    "        message,\n",
    "        account_collection,\n",
    "        sentence_transformer,\n",
    "        n_results=10\n",
    "    )\n",
    "\n",
    "    ids = res[\"ids\"][0]\n",
    "    matches = df[df[\"opportunity_id\"].isin(ids)].copy()\n",
    "    matches[\"__rank\"] = matches[\"opportunity_id\"].apply(lambda x: ids.index(x))\n",
    "    matches = matches.sort_values(\"__rank\").drop(columns=\"__rank\")\n",
    "\n",
    "    # keep only the most useful columns for display\n",
    "    cols = [\n",
    "        \"opportunity_id\", \"sales_agent\", \"product\", \"account\",\n",
    "        \"deal_stage\", \"engage_date\", \"close_date\",\n",
    "        \"revenue\", \"employees\", \"office_location\"\n",
    "    ]\n",
    "    matches = matches[cols]\n",
    "\n",
    "    table_md = matches.to_markdown(index=False)\n",
    "\n",
    "    response = (\n",
    "        f\"Here are the opportunities I found that match your query:\\n\\n\"\n",
    "        f\"{table_md}\\n\\n\"\n",
    "        f\"Ask another question or refine your query!\"\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    chat_fn,\n",
    "    title=\"Salesforce 2A\",\n",
    "    description=\"Hi! I can help you explore Salesforce CRM opportunities and accounts. What would you like to know?\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
